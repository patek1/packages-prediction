{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "file_path = \"C:/Users/patri/OneDrive/Documents/!HSG/DSF/project/\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>weekday</th>\n",
       "      <th>postcode</th>\n",
       "      <th>product</th>\n",
       "      <th>packages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01/01/2020</td>\n",
       "      <td>DI</td>\n",
       "      <td>9000</td>\n",
       "      <td>ECO</td>\n",
       "      <td>4251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01/01/2020</td>\n",
       "      <td>DI</td>\n",
       "      <td>9000</td>\n",
       "      <td>SEM</td>\n",
       "      <td>274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01/01/2020</td>\n",
       "      <td>DI</td>\n",
       "      <td>9000</td>\n",
       "      <td>PRI</td>\n",
       "      <td>9350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>01/01/2020</td>\n",
       "      <td>DI</td>\n",
       "      <td>9001</td>\n",
       "      <td>PRI</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>01/01/2020</td>\n",
       "      <td>DI</td>\n",
       "      <td>9001</td>\n",
       "      <td>ECO</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86528</th>\n",
       "      <td>01/12/2021</td>\n",
       "      <td>DI</td>\n",
       "      <td>9657</td>\n",
       "      <td>ECO</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86529</th>\n",
       "      <td>01/12/2021</td>\n",
       "      <td>DI</td>\n",
       "      <td>9657</td>\n",
       "      <td>SEM</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86544</th>\n",
       "      <td>01/12/2021</td>\n",
       "      <td>DI</td>\n",
       "      <td>9658</td>\n",
       "      <td>ECO</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86545</th>\n",
       "      <td>01/12/2021</td>\n",
       "      <td>DI</td>\n",
       "      <td>9658</td>\n",
       "      <td>SEM</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86546</th>\n",
       "      <td>01/12/2021</td>\n",
       "      <td>DI</td>\n",
       "      <td>9658</td>\n",
       "      <td>PRI</td>\n",
       "      <td>374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14719 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            month weekday  postcode product  packages\n",
       "0      01/01/2020      DI      9000     ECO      4251\n",
       "1      01/01/2020      DI      9000     SEM       274\n",
       "2      01/01/2020      DI      9000     PRI      9350\n",
       "20     01/01/2020      DI      9001     PRI        40\n",
       "21     01/01/2020      DI      9001     ECO        50\n",
       "...           ...     ...       ...     ...       ...\n",
       "86528  01/12/2021      DI      9657     ECO        93\n",
       "86529  01/12/2021      DI      9657     SEM         4\n",
       "86544  01/12/2021      DI      9658     ECO       152\n",
       "86545  01/12/2021      DI      9658     SEM         8\n",
       "86546  01/12/2021      DI      9658     PRI       374\n",
       "\n",
       "[14719 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the primary data set from 2020, rename columns\n",
    "packages_agg = pd.read_csv(file_path + \"packages_both_years.csv\")\n",
    "packages_agg.rename(columns={\"MONAT\": \"month\", \"PRODUKT_GRUPPE\": \"product\", \"PLZ\": \"postcode\", \"WOCHENTAG\": \"weekday\", \"ANZAHL\": \"packages\"}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have 3 variants of dispatching (ECO, PRI, SEM), we want to get the aggregate number of packages\n",
    "# thus we we group by postcode, month, weekday and then take the sum of the dispatchments\n",
    "packages_grouped = packages_agg.groupby([\"postcode\", \"month\", \"weekday\"]).agg(sum=(\"packages\", \"sum\"))\n",
    "\n",
    "# we reset the index and rename the sum column to packages\n",
    "packages_grouped.reset_index(inplace=True)\n",
    "packages_grouped.rename(columns={\"sum\": \"packages\"}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need the bfs number, which is different from the postal code, \n",
    "# to merge with our other features! Thus we first merge our data with the bfs number data.\n",
    "\n",
    "# read the data with the bfs numbers and rename the columns\n",
    "bfs_number = pd.read_csv(file_path + \"features_csv/plz_bfs.csv\", sep=\";\") \n",
    "bfs_number.rename(columns={\"PLZ\": \"postcode\", \"BFS-Nr\": \"bfs_no\"}, inplace = True)\n",
    "bfs_number = bfs_number.loc[(bfs_number[\"Kantonskürzel\"] == \"SG\")]\n",
    "\n",
    "# ESSENTIAL step; we need to remove the duplicate entries in the postcode column\n",
    "# since otherwise we'll have an indistict mapping from postcode to bfs number and thus\n",
    "# additional rows will be added that originally did not exist (see more below).\n",
    "bfs_number.drop_duplicates(subset=[\"postcode\"], inplace=True)\n",
    "\n",
    "# merge the data: we use a left merge since the important data is the \"packages\" data set\n",
    "# and we only want to add those bfs numbers to which we have a corresponding postcode.\n",
    "mergeA = pd.merge(packages_grouped, bfs_number[[\"postcode\", \"bfs_no\"]], how = \"left\", on=\"postcode\")\n",
    "\n",
    "# # In our data we have municipalities from St. Gallen, Appenzell IR/AR, Liechtenstein, and \n",
    "# some of Thurgau. However, we did not find any data for the municipalities of Appenzell IR/AR,\n",
    "# Liechtenstein, and Thurgau for our features, even when we called them :/\n",
    "# So we drop the rows of those municipalities for which we do not have data, i.e., a bfs number!\n",
    "mergeA.dropna(subset=\"bfs_no\", inplace = True)\n",
    "\n",
    "# we aggregate the packages by the bfs number\n",
    "master_data = mergeA.groupby([\"bfs_no\", \"month\", \"weekday\"]).agg(sum=(\"packages\", \"sum\"))\n",
    "\n",
    "# reset the index and rename the column\n",
    "master_data.reset_index(inplace=True)\n",
    "master_data.rename(columns={\"sum\": \"packages\"}, inplace = True)\n",
    "\n",
    "# convert the bfs number and the packages back to integers\n",
    "master_data[[\"packages\", \"bfs_no\"]] = master_data[[\"packages\", \"bfs_no\"]].astype(int)\n",
    "\n",
    "# save the master data\n",
    "# master_data.to_csv(file_path + \"master_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we inspected our mistake, we had multiple rows containing the same postcode \n",
    "# and the same bfs number...fallacy!!\n",
    "# test = bfs_number.groupby(\"postcode\").count().reset_index().sort_values(\"bfs_no\")\n",
    "# test.loc[(test[\"bfs_no\"] > 1) & (test[\"postcode\"] >= 9000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jonathan (Chassot) showing us how the mapping error is possible when we have multiple rows\n",
    "# that contain the same postcode, however it was a fallacy to think we have multiple bfs \n",
    "# numbers per postcode, the reason was we had multiple rows containing the same postcode \n",
    "# AND bfs number!\n",
    "\n",
    "# df1 = pd.DataFrame({\"postcode\": [9000,8000,6000], \"packages\": [1,2,3]})\n",
    "# df2 = pd.DataFrame({\"postcode\": [9000, 9000], \"bfs-nr\": [1,2]})\n",
    "# pd.merge(df1, df2, how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide the master dataset into 2020 and 2021\n",
    "packages_2021 = master_data.loc[(master_data[\"month\"] == \"01/01/2021\") | (master_data[\"month\"] == \"01/02/2021\") | (master_data[\"month\"] == \"01/03/2021\") | (master_data[\"month\"] == \"01/04/2021\") | (master_data[\"month\"] == \"01/05/2021\") | (master_data[\"month\"] == \"01/06/2021\") | (master_data[\"month\"] == \"01/07/2021\") | (master_data[\"month\"] == \"01/08/2021\") | (master_data[\"month\"] == \"01/09/2021\") | (master_data[\"month\"] == \"01/10/2021\") | (master_data[\"month\"] == \"01/11/2021\") | (master_data[\"month\"] == \"01/12/2021\")].reset_index(drop=True)\n",
    "packages_2020 = master_data.loc[(master_data[\"month\"] == \"01/01/2020\") | (master_data[\"month\"] == \"01/02/2020\") | (master_data[\"month\"] == \"01/03/2020\") | (master_data[\"month\"] == \"01/04/2020\") | (master_data[\"month\"] == \"01/05/2020\") | (master_data[\"month\"] == \"01/06/2020\") | (master_data[\"month\"] == \"01/07/2020\") | (master_data[\"month\"] == \"01/08/2020\") | (master_data[\"month\"] == \"01/09/2020\") | (master_data[\"month\"] == \"01/10/2020\") | (master_data[\"month\"] == \"01/11/2020\") | (master_data[\"month\"] == \"01/12/2020\")].reset_index(drop=True)\n",
    "\n",
    "# since we're not interested whether it's the particular december in 2021, but just whether it's december or not!\n",
    "packages_2021[\"month\"] = packages_2021[\"month\"].map({\"01/01/2021\": \"January\", \"01/02/2021\": \"February\", \"01/03/2021\": \"March\", \"01/04/2021\": \"April\", \"01/05/2021\": \"May\", \"01/06/2021\": \"June\", \"01/07/2021\": \"July\", \"01/08/2021\": \"August\", \"01/09/2021\": \"September\", \"01/10/2021\": \"October\", \"01/11/2021\": \"November\", \"01/12/2021\": \"December\"})\n",
    "packages_2020[\"month\"] = packages_2020[\"month\"].map({\"01/01/2020\": \"January\", \"01/02/2020\": \"February\", \"01/03/2020\": \"March\", \"01/04/2020\": \"April\", \"01/05/2020\": \"May\", \"01/06/2020\": \"June\", \"01/07/2020\": \"July\", \"01/08/2020\": \"August\", \"01/09/2020\": \"September\", \"01/10/2020\": \"October\", \"01/11/2020\": \"November\", \"01/12/2020\": \"December\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data for the mean age, keep only relevant columns and rename them \n",
    "age = pd.read_csv(file_path + \"features_csv/mean_age.csv\", usecols=[\"BFS_NR\", \"2021\", \"2020\"])\n",
    "age.rename(columns={\"BFS_NR\": \"bfs_no\", \"2021\": \"mean_age_2021\", \"2020\": \"mean_age_2020\"}, inplace=True)\n",
    "# merge the master data with the age data\n",
    "merge_age_2020 = pd.merge(packages_2020, age[[\"bfs_no\", \"mean_age_2020\"]], how=\"left\", on=\"bfs_no\")\n",
    "merge_age_2021 = pd.merge(packages_2021, age[[\"bfs_no\", \"mean_age_2021\"]], how=\"left\", on=\"bfs_no\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data for the permanent total population and for the % of population in certain\n",
    "# age range and rename columns\n",
    "from glob import glob\n",
    "\n",
    "# use the function glob to catch all population data files and easily combine them into one population dataset (with concat)\n",
    "popdata_list = sorted(glob(file_path + \"features_csv/population_data/population*\"))\n",
    "\n",
    "# merge all the data we have for the years 2020 to 2021 into one merged population df\n",
    "merged_pop = pd.concat((pd.read_csv(file, usecols=[\"BFS_NR\", \"2021\", \"2020\"]) for file in popdata_list), ignore_index=True, axis=1)\n",
    "# we drop the addtional columnns that contain the bfs number as well\n",
    "merged_pop.drop(columns=[3, 6, 9, 12, 15, 18], inplace=True)\n",
    "# rename the columns\n",
    "merged_pop.rename(columns={0: \"bfs_no\", 1: \"total_pop2021\", 2: \"total_pop2020\", 4: \"share2021_0to14\", 5: \"share2020_0to14\", 7: \"share2021_15to19\", 8: \"share2020_15to19\", 10: \"share2021_20to39\", 11:\"share2020_20to39\", 13: \"share2021_40to64\", 14: \"share2020_40to64\", 16: \"share2021_65to79\", 17: \"share2020_65to79\", 19: \"share2021_above80\", 20: \"share2020_above80\"}, inplace = True)\n",
    "\n",
    "# merge the data on the primary datasets\n",
    "merge_pop_2020 = pd.merge(merge_age_2020, merged_pop[[\"bfs_no\", \"total_pop2020\", \"share2020_0to14\", \"share2020_15to19\", \"share2020_20to39\", \"share2020_40to64\", \"share2020_65to79\", \"share2020_above80\"]], how=\"left\", on=\"bfs_no\") \n",
    "merge_pop_2021 = pd.merge(merge_age_2021, merged_pop[[\"bfs_no\", \"total_pop2021\", \"share2021_0to14\", \"share2021_15to19\", \"share2021_20to39\", \"share2021_40to64\", \"share2021_65to79\", \"share2021_above80\"]], how=\"left\", on=\"bfs_no\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read and rename columns of foreigner share\n",
    "foreigners = pd.read_csv(\"C:/Users/patri/Downloads/features_csv/foreigners_share.csv\", usecols=[\"BFS_NR\", \"2021\", \"2020\"])\n",
    "foreigners.rename(columns={\"BFS_NR\": \"bfs_no\", \"2021\": \"foreigners_2021\", \"2020\": \"foreigners_2020\"}, inplace=True)\n",
    "\n",
    "# merge\n",
    "merge_for_2020 = pd.merge(merge_pop_2020, foreigners[[\"bfs_no\", \"foreigners_2020\"]], how=\"left\", on=\"bfs_no\")\n",
    "merge_for_2021 = pd.merge(merge_pop_2021, foreigners[[\"bfs_no\", \"foreigners_2021\"]], how=\"left\", on=\"bfs_no\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read and rename columns of share of catholics, protestants and other religions\n",
    "religion_data = sorted(glob(file_path + \"features_csv/religion_data/religion*\"))\n",
    "\n",
    "merged_religion = pd.concat((pd.read_csv(file, usecols=[\"BFS_NR\", \"2021\", \"2020\"]) for file in religion_data), ignore_index=True, axis=1)\n",
    "merged_religion.rename(columns={0: \"bfs_no\", 1:\"catholics2021\", 2: \"catholics2020\", 4:\"other_relig_2021\", 5: \"other_relig_2020\", 7: \"protestants_2021\", 8: \"protestants_2020\"}, inplace= True)\n",
    "merged_religion.drop(columns=[3, 6], inplace = True)\n",
    "\n",
    "# merge, merge, merge\n",
    "merge_relig2020 = pd.merge(merge_for_2020, merged_religion[[\"bfs_no\", \"catholics2020\", \"other_relig_2020\", \"protestants_2020\"]], how=\"left\", on=\"bfs_no\")\n",
    "merge_relig2021 = pd.merge(merge_for_2021, merged_religion[[\"bfs_no\", \"catholics2021\", \"other_relig_2021\", \"protestants_2021\"]], how=\"left\", on=\"bfs_no\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read and rename columns of the unemployment data\n",
    "unemployment = pd.read_csv(file_path + \"features_csv/unemployment.csv\", usecols=[\"BFS_NR\", \"2021\", \"2020\"])\n",
    "unemployment.rename(columns={\"BFS_NR\": \"bfs_no\", \"2021\": \"unemployment2021\", \"2020\": \"unemployment2020\"}, inplace=True)\n",
    "\n",
    "# merge\n",
    "merge_unemp2020 = pd.merge(merge_relig2020, unemployment[[\"bfs_no\", \"unemployment2020\"]], how=\"left\", on=\"bfs_no\")\n",
    "merge_unemp2021 = pd.merge(merge_relig2021, unemployment[[\"bfs_no\", \"unemployment2021\"]], how=\"left\", on=\"bfs_no\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bfs_no</th>\n",
       "      <th>month</th>\n",
       "      <th>weekday</th>\n",
       "      <th>packages</th>\n",
       "      <th>mean_age</th>\n",
       "      <th>total_pop</th>\n",
       "      <th>share_0to14</th>\n",
       "      <th>share_15to19</th>\n",
       "      <th>share_20to39</th>\n",
       "      <th>share_40to64</th>\n",
       "      <th>share_65to79</th>\n",
       "      <th>share_above80</th>\n",
       "      <th>share_foreigners</th>\n",
       "      <th>share_catholics</th>\n",
       "      <th>share_other_relig</th>\n",
       "      <th>share_protestants</th>\n",
       "      <th>unemployment_rate</th>\n",
       "      <th>tax_power2021</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3201</td>\n",
       "      <td>January</td>\n",
       "      <td>DI</td>\n",
       "      <td>490</td>\n",
       "      <td>39.5</td>\n",
       "      <td>1'376</td>\n",
       "      <td>20.9</td>\n",
       "      <td>4.8</td>\n",
       "      <td>25.2</td>\n",
       "      <td>33.9</td>\n",
       "      <td>10.8</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.7</td>\n",
       "      <td>55.3</td>\n",
       "      <td>24.3</td>\n",
       "      <td>20.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>91.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3201</td>\n",
       "      <td>January</td>\n",
       "      <td>DO</td>\n",
       "      <td>464</td>\n",
       "      <td>39.5</td>\n",
       "      <td>1'376</td>\n",
       "      <td>20.9</td>\n",
       "      <td>4.8</td>\n",
       "      <td>25.2</td>\n",
       "      <td>33.9</td>\n",
       "      <td>10.8</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.7</td>\n",
       "      <td>55.3</td>\n",
       "      <td>24.3</td>\n",
       "      <td>20.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>91.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3201</td>\n",
       "      <td>January</td>\n",
       "      <td>FR</td>\n",
       "      <td>355</td>\n",
       "      <td>39.5</td>\n",
       "      <td>1'376</td>\n",
       "      <td>20.9</td>\n",
       "      <td>4.8</td>\n",
       "      <td>25.2</td>\n",
       "      <td>33.9</td>\n",
       "      <td>10.8</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.7</td>\n",
       "      <td>55.3</td>\n",
       "      <td>24.3</td>\n",
       "      <td>20.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>91.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3201</td>\n",
       "      <td>January</td>\n",
       "      <td>MI</td>\n",
       "      <td>493</td>\n",
       "      <td>39.5</td>\n",
       "      <td>1'376</td>\n",
       "      <td>20.9</td>\n",
       "      <td>4.8</td>\n",
       "      <td>25.2</td>\n",
       "      <td>33.9</td>\n",
       "      <td>10.8</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.7</td>\n",
       "      <td>55.3</td>\n",
       "      <td>24.3</td>\n",
       "      <td>20.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>91.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3201</td>\n",
       "      <td>January</td>\n",
       "      <td>MO</td>\n",
       "      <td>267</td>\n",
       "      <td>39.5</td>\n",
       "      <td>1'376</td>\n",
       "      <td>20.9</td>\n",
       "      <td>4.8</td>\n",
       "      <td>25.2</td>\n",
       "      <td>33.9</td>\n",
       "      <td>10.8</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.7</td>\n",
       "      <td>55.3</td>\n",
       "      <td>24.3</td>\n",
       "      <td>20.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>91.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4258</th>\n",
       "      <td>3444</td>\n",
       "      <td>December</td>\n",
       "      <td>DO</td>\n",
       "      <td>1874</td>\n",
       "      <td>40.2</td>\n",
       "      <td>3'569</td>\n",
       "      <td>19.9</td>\n",
       "      <td>6.2</td>\n",
       "      <td>22.0</td>\n",
       "      <td>35.8</td>\n",
       "      <td>11.2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>8.2</td>\n",
       "      <td>57.4</td>\n",
       "      <td>24.</td>\n",
       "      <td>18.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>86.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4259</th>\n",
       "      <td>3444</td>\n",
       "      <td>December</td>\n",
       "      <td>FR</td>\n",
       "      <td>1682</td>\n",
       "      <td>40.2</td>\n",
       "      <td>3'569</td>\n",
       "      <td>19.9</td>\n",
       "      <td>6.2</td>\n",
       "      <td>22.0</td>\n",
       "      <td>35.8</td>\n",
       "      <td>11.2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>8.2</td>\n",
       "      <td>57.4</td>\n",
       "      <td>24.</td>\n",
       "      <td>18.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>86.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4260</th>\n",
       "      <td>3444</td>\n",
       "      <td>December</td>\n",
       "      <td>MI</td>\n",
       "      <td>1969</td>\n",
       "      <td>40.2</td>\n",
       "      <td>3'569</td>\n",
       "      <td>19.9</td>\n",
       "      <td>6.2</td>\n",
       "      <td>22.0</td>\n",
       "      <td>35.8</td>\n",
       "      <td>11.2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>8.2</td>\n",
       "      <td>57.4</td>\n",
       "      <td>24.</td>\n",
       "      <td>18.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>86.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4261</th>\n",
       "      <td>3444</td>\n",
       "      <td>December</td>\n",
       "      <td>MO</td>\n",
       "      <td>338</td>\n",
       "      <td>40.2</td>\n",
       "      <td>3'569</td>\n",
       "      <td>19.9</td>\n",
       "      <td>6.2</td>\n",
       "      <td>22.0</td>\n",
       "      <td>35.8</td>\n",
       "      <td>11.2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>8.2</td>\n",
       "      <td>57.4</td>\n",
       "      <td>24.</td>\n",
       "      <td>18.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>86.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4262</th>\n",
       "      <td>3444</td>\n",
       "      <td>December</td>\n",
       "      <td>SA</td>\n",
       "      <td>1027</td>\n",
       "      <td>40.2</td>\n",
       "      <td>3'569</td>\n",
       "      <td>19.9</td>\n",
       "      <td>6.2</td>\n",
       "      <td>22.0</td>\n",
       "      <td>35.8</td>\n",
       "      <td>11.2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>8.2</td>\n",
       "      <td>57.4</td>\n",
       "      <td>24.</td>\n",
       "      <td>18.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>86.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4263 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      bfs_no     month weekday  packages  mean_age total_pop  share_0to14  \\\n",
       "0       3201   January      DI       490      39.5     1'376         20.9   \n",
       "1       3201   January      DO       464      39.5     1'376         20.9   \n",
       "2       3201   January      FR       355      39.5     1'376         20.9   \n",
       "3       3201   January      MI       493      39.5     1'376         20.9   \n",
       "4       3201   January      MO       267      39.5     1'376         20.9   \n",
       "...      ...       ...     ...       ...       ...       ...          ...   \n",
       "4258    3444  December      DO      1874      40.2     3'569         19.9   \n",
       "4259    3444  December      FR      1682      40.2     3'569         19.9   \n",
       "4260    3444  December      MI      1969      40.2     3'569         19.9   \n",
       "4261    3444  December      MO       338      40.2     3'569         19.9   \n",
       "4262    3444  December      SA      1027      40.2     3'569         19.9   \n",
       "\n",
       "      share_15to19  share_20to39  share_40to64  share_65to79  share_above80  \\\n",
       "0              4.8          25.2          33.9          10.8            4.5   \n",
       "1              4.8          25.2          33.9          10.8            4.5   \n",
       "2              4.8          25.2          33.9          10.8            4.5   \n",
       "3              4.8          25.2          33.9          10.8            4.5   \n",
       "4              4.8          25.2          33.9          10.8            4.5   \n",
       "...            ...           ...           ...           ...            ...   \n",
       "4258           6.2          22.0          35.8          11.2            4.9   \n",
       "4259           6.2          22.0          35.8          11.2            4.9   \n",
       "4260           6.2          22.0          35.8          11.2            4.9   \n",
       "4261           6.2          22.0          35.8          11.2            4.9   \n",
       "4262           6.2          22.0          35.8          11.2            4.9   \n",
       "\n",
       "      share_foreigners share_catholics share_other_relig share_protestants  \\\n",
       "0                  9.7            55.3              24.3              20.3   \n",
       "1                  9.7            55.3              24.3              20.3   \n",
       "2                  9.7            55.3              24.3              20.3   \n",
       "3                  9.7            55.3              24.3              20.3   \n",
       "4                  9.7            55.3              24.3              20.3   \n",
       "...                ...             ...               ...               ...   \n",
       "4258               8.2            57.4               24.              18.6   \n",
       "4259               8.2            57.4               24.              18.6   \n",
       "4260               8.2            57.4               24.              18.6   \n",
       "4261               8.2            57.4               24.              18.6   \n",
       "4262               8.2            57.4               24.              18.6   \n",
       "\n",
       "      unemployment_rate tax_power2021  \n",
       "0                   0.8          91.1  \n",
       "1                   0.8          91.1  \n",
       "2                   0.8          91.1  \n",
       "3                   0.8          91.1  \n",
       "4                   0.8          91.1  \n",
       "...                 ...           ...  \n",
       "4258                0.9          86.7  \n",
       "4259                0.9          86.7  \n",
       "4260                0.9          86.7  \n",
       "4261                0.9          86.7  \n",
       "4262                0.9          86.7  \n",
       "\n",
       "[4263 rows x 18 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read and rename columns of the tax power data\n",
    "tax_power = pd.read_csv(file_path + \"features_csv/tax_power.csv\", usecols=[\"BFS_NR\", \"2021\", \"2020\"])\n",
    "tax_power.rename(columns={\"BFS_NR\": \"bfs_no\", \"2021\": \"tax_power2021\", \"2020\": \"tax_power2020\"}, inplace = True)\n",
    "\n",
    "# merge\n",
    "merge_tax2020 = pd.merge(merge_unemp2020, tax_power[[\"bfs_no\", \"tax_power2020\"]], how=\"left\", on=\"bfs_no\")\n",
    "merge_tax2021 = pd.merge(merge_unemp2021, tax_power[[\"bfs_no\", \"tax_power2021\"]], how=\"left\", on=\"bfs_no\")\n",
    "#merge_tax2021.rename(columns={'tax_power2021': 'taxpower'}, inplace = True)\n",
    "merge_tax2021\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read and rename columns of tertiary education \n",
    "tertiary_edu = pd.read_csv(\"C:/Users/patri/Downloads/features_csv/share_tertiary_edu.csv\", usecols=[\"BFS_NR\", \"2020\"])\n",
    "tertiary_edu.rename(columns={\"BFS_NR\": \"bfs_no\", \"2020\": \"share_tertiary\"}, inplace=True)\n",
    "\n",
    "# merge\n",
    "merge_edu2020 = pd.merge(merge_tax2020, tertiary_edu, how=\"left\", on=\"bfs_no\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read and rename columns of the number of firms data\n",
    "firms = pd.read_csv(file_path + \"features_csv/firms.csv\", usecols=[\"BFS_NR\", \"2020\"])\n",
    "firms.rename(columns={\"BFS_NR\": \"bfs_no\", \"2020\": \"firms\"}, inplace=True)\n",
    "\n",
    "# merge and change type to intger\n",
    "merge_firms2020 = pd.merge(merge_edu2020, firms, how=\"left\", on=\"bfs_no\")\n",
    "merge_firms2020[\"firms\"] = merge_firms2020[\"firms\"].str.replace(\"'\", \"\",).astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bfs_no</th>\n",
       "      <th>month</th>\n",
       "      <th>weekday</th>\n",
       "      <th>packages</th>\n",
       "      <th>mean_age</th>\n",
       "      <th>total_pop</th>\n",
       "      <th>share_0to14</th>\n",
       "      <th>share_15to19</th>\n",
       "      <th>share_20to39</th>\n",
       "      <th>share_40to64</th>\n",
       "      <th>share_65to79</th>\n",
       "      <th>share_above80</th>\n",
       "      <th>share_foreigners</th>\n",
       "      <th>share_catholics</th>\n",
       "      <th>share_other_relig</th>\n",
       "      <th>share_protestants</th>\n",
       "      <th>unemployment_rate</th>\n",
       "      <th>taxpower</th>\n",
       "      <th>share_tertiary</th>\n",
       "      <th>firms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3201</td>\n",
       "      <td>January</td>\n",
       "      <td>DI</td>\n",
       "      <td>403</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1'389</td>\n",
       "      <td>20.9</td>\n",
       "      <td>5.1</td>\n",
       "      <td>26.1</td>\n",
       "      <td>33.8</td>\n",
       "      <td>9.4</td>\n",
       "      <td>4.8</td>\n",
       "      <td>8.4</td>\n",
       "      <td>57.</td>\n",
       "      <td>21.7</td>\n",
       "      <td>21.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>90.9</td>\n",
       "      <td>59.9</td>\n",
       "      <td>106.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3201</td>\n",
       "      <td>January</td>\n",
       "      <td>DO</td>\n",
       "      <td>359</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1'389</td>\n",
       "      <td>20.9</td>\n",
       "      <td>5.1</td>\n",
       "      <td>26.1</td>\n",
       "      <td>33.8</td>\n",
       "      <td>9.4</td>\n",
       "      <td>4.8</td>\n",
       "      <td>8.4</td>\n",
       "      <td>57.</td>\n",
       "      <td>21.7</td>\n",
       "      <td>21.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>90.9</td>\n",
       "      <td>59.9</td>\n",
       "      <td>106.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3201</td>\n",
       "      <td>January</td>\n",
       "      <td>FR</td>\n",
       "      <td>357</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1'389</td>\n",
       "      <td>20.9</td>\n",
       "      <td>5.1</td>\n",
       "      <td>26.1</td>\n",
       "      <td>33.8</td>\n",
       "      <td>9.4</td>\n",
       "      <td>4.8</td>\n",
       "      <td>8.4</td>\n",
       "      <td>57.</td>\n",
       "      <td>21.7</td>\n",
       "      <td>21.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>90.9</td>\n",
       "      <td>59.9</td>\n",
       "      <td>106.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3201</td>\n",
       "      <td>January</td>\n",
       "      <td>MI</td>\n",
       "      <td>346</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1'389</td>\n",
       "      <td>20.9</td>\n",
       "      <td>5.1</td>\n",
       "      <td>26.1</td>\n",
       "      <td>33.8</td>\n",
       "      <td>9.4</td>\n",
       "      <td>4.8</td>\n",
       "      <td>8.4</td>\n",
       "      <td>57.</td>\n",
       "      <td>21.7</td>\n",
       "      <td>21.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>90.9</td>\n",
       "      <td>59.9</td>\n",
       "      <td>106.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3201</td>\n",
       "      <td>January</td>\n",
       "      <td>MO</td>\n",
       "      <td>230</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1'389</td>\n",
       "      <td>20.9</td>\n",
       "      <td>5.1</td>\n",
       "      <td>26.1</td>\n",
       "      <td>33.8</td>\n",
       "      <td>9.4</td>\n",
       "      <td>4.8</td>\n",
       "      <td>8.4</td>\n",
       "      <td>57.</td>\n",
       "      <td>21.7</td>\n",
       "      <td>21.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>90.9</td>\n",
       "      <td>59.9</td>\n",
       "      <td>106.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8567</th>\n",
       "      <td>3444</td>\n",
       "      <td>December</td>\n",
       "      <td>DO</td>\n",
       "      <td>1874</td>\n",
       "      <td>40.2</td>\n",
       "      <td>3'569</td>\n",
       "      <td>19.9</td>\n",
       "      <td>6.2</td>\n",
       "      <td>22.0</td>\n",
       "      <td>35.8</td>\n",
       "      <td>11.2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>8.2</td>\n",
       "      <td>57.4</td>\n",
       "      <td>24.</td>\n",
       "      <td>18.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>86.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8568</th>\n",
       "      <td>3444</td>\n",
       "      <td>December</td>\n",
       "      <td>FR</td>\n",
       "      <td>1682</td>\n",
       "      <td>40.2</td>\n",
       "      <td>3'569</td>\n",
       "      <td>19.9</td>\n",
       "      <td>6.2</td>\n",
       "      <td>22.0</td>\n",
       "      <td>35.8</td>\n",
       "      <td>11.2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>8.2</td>\n",
       "      <td>57.4</td>\n",
       "      <td>24.</td>\n",
       "      <td>18.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>86.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8569</th>\n",
       "      <td>3444</td>\n",
       "      <td>December</td>\n",
       "      <td>MI</td>\n",
       "      <td>1969</td>\n",
       "      <td>40.2</td>\n",
       "      <td>3'569</td>\n",
       "      <td>19.9</td>\n",
       "      <td>6.2</td>\n",
       "      <td>22.0</td>\n",
       "      <td>35.8</td>\n",
       "      <td>11.2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>8.2</td>\n",
       "      <td>57.4</td>\n",
       "      <td>24.</td>\n",
       "      <td>18.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>86.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8570</th>\n",
       "      <td>3444</td>\n",
       "      <td>December</td>\n",
       "      <td>MO</td>\n",
       "      <td>338</td>\n",
       "      <td>40.2</td>\n",
       "      <td>3'569</td>\n",
       "      <td>19.9</td>\n",
       "      <td>6.2</td>\n",
       "      <td>22.0</td>\n",
       "      <td>35.8</td>\n",
       "      <td>11.2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>8.2</td>\n",
       "      <td>57.4</td>\n",
       "      <td>24.</td>\n",
       "      <td>18.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>86.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8571</th>\n",
       "      <td>3444</td>\n",
       "      <td>December</td>\n",
       "      <td>SA</td>\n",
       "      <td>1027</td>\n",
       "      <td>40.2</td>\n",
       "      <td>3'569</td>\n",
       "      <td>19.9</td>\n",
       "      <td>6.2</td>\n",
       "      <td>22.0</td>\n",
       "      <td>35.8</td>\n",
       "      <td>11.2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>8.2</td>\n",
       "      <td>57.4</td>\n",
       "      <td>24.</td>\n",
       "      <td>18.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>86.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8572 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      bfs_no     month weekday  packages  mean_age total_pop  share_0to14  \\\n",
       "0       3201   January      DI       403      39.0     1'389         20.9   \n",
       "1       3201   January      DO       359      39.0     1'389         20.9   \n",
       "2       3201   January      FR       357      39.0     1'389         20.9   \n",
       "3       3201   January      MI       346      39.0     1'389         20.9   \n",
       "4       3201   January      MO       230      39.0     1'389         20.9   \n",
       "...      ...       ...     ...       ...       ...       ...          ...   \n",
       "8567    3444  December      DO      1874      40.2     3'569         19.9   \n",
       "8568    3444  December      FR      1682      40.2     3'569         19.9   \n",
       "8569    3444  December      MI      1969      40.2     3'569         19.9   \n",
       "8570    3444  December      MO       338      40.2     3'569         19.9   \n",
       "8571    3444  December      SA      1027      40.2     3'569         19.9   \n",
       "\n",
       "      share_15to19  share_20to39  share_40to64  share_65to79  share_above80  \\\n",
       "0              5.1          26.1          33.8           9.4            4.8   \n",
       "1              5.1          26.1          33.8           9.4            4.8   \n",
       "2              5.1          26.1          33.8           9.4            4.8   \n",
       "3              5.1          26.1          33.8           9.4            4.8   \n",
       "4              5.1          26.1          33.8           9.4            4.8   \n",
       "...            ...           ...           ...           ...            ...   \n",
       "8567           6.2          22.0          35.8          11.2            4.9   \n",
       "8568           6.2          22.0          35.8          11.2            4.9   \n",
       "8569           6.2          22.0          35.8          11.2            4.9   \n",
       "8570           6.2          22.0          35.8          11.2            4.9   \n",
       "8571           6.2          22.0          35.8          11.2            4.9   \n",
       "\n",
       "      share_foreigners share_catholics share_other_relig share_protestants  \\\n",
       "0                  8.4             57.              21.7              21.2   \n",
       "1                  8.4             57.              21.7              21.2   \n",
       "2                  8.4             57.              21.7              21.2   \n",
       "3                  8.4             57.              21.7              21.2   \n",
       "4                  8.4             57.              21.7              21.2   \n",
       "...                ...             ...               ...               ...   \n",
       "8567               8.2            57.4               24.              18.6   \n",
       "8568               8.2            57.4               24.              18.6   \n",
       "8569               8.2            57.4               24.              18.6   \n",
       "8570               8.2            57.4               24.              18.6   \n",
       "8571               8.2            57.4               24.              18.6   \n",
       "\n",
       "      unemployment_rate taxpower  share_tertiary  firms  \n",
       "0                   0.8     90.9            59.9  106.0  \n",
       "1                   0.8     90.9            59.9  106.0  \n",
       "2                   0.8     90.9            59.9  106.0  \n",
       "3                   0.8     90.9            59.9  106.0  \n",
       "4                   0.8     90.9            59.9  106.0  \n",
       "...                 ...      ...             ...    ...  \n",
       "8567                0.9     86.7             NaN    NaN  \n",
       "8568                0.9     86.7             NaN    NaN  \n",
       "8569                0.9     86.7             NaN    NaN  \n",
       "8570                0.9     86.7             NaN    NaN  \n",
       "8571                0.9     86.7             NaN    NaN  \n",
       "\n",
       "[8572 rows x 20 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we had to rename the columns with the corresponding year in oder to merge it with the\n",
    "# right data half. Now, we need to rename them again in order to have them concatenated\n",
    "# on the same columns!\n",
    "\n",
    "# merge_firms2020.columns\n",
    "merge_firms2020.rename(columns={'mean_age_2020': 'mean_age',\n",
    "       'total_pop2020': 'total_pop', 'share2020_0to14': 'share_0to14', 'share2020_15to19': 'share_15to19',\n",
    "       'share2020_20to39':  'share_20to39', 'share2020_40to64': 'share_40to64', 'share2020_65to79': 'share_65to79',\n",
    "       'share2020_above80': 'share_above80', 'foreigners_2020': 'share_foreigners', 'catholics2020': 'share_catholics',\n",
    "       'other_relig_2020': 'share_other_relig', 'protestants_2020': 'share_protestants', 'unemployment2020': 'unemployment_rate',\n",
    "       'tax_power2020': 'taxpower'}, inplace = True)\n",
    "\n",
    "\n",
    "# merge_unemp2021.columns\n",
    "merge_tax2021.rename(columns={'mean_age_2021': 'mean_age',\n",
    "       'total_pop2021': 'total_pop', 'share2021_0to14': 'share_0to14', 'share2021_15to19': 'share_15to19',\n",
    "       'share2021_20to39':  'share_20to39', 'share2021_40to64': 'share_40to64', 'share2021_65to79': 'share_65to79',\n",
    "       'share2021_above80': 'share_above80', 'foreigners_2021': 'share_foreigners', 'catholics2021': 'share_catholics',\n",
    "       'other_relig_2021': 'share_other_relig', 'protestants_2021': 'share_protestants', 'unemployment2021': 'unemployment_rate',\n",
    "       'tax_power2021': 'taxpower'}, inplace = True)\n",
    "\n",
    "# concatenate the two data sets\n",
    "concat_data = pd.concat([merge_firms2020, merge_tax2021], join=\"outer\", ignore_index=True)\n",
    "\n",
    "concat_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the coordinates (we need them to compute the distance to the nearest city)\n",
    "merge_geo = pd.merge(concat_data, bfs_number[[\"bfs_no\", \"E\", \"N\"]].drop_duplicates(subset=\"bfs_no\"), how=\"left\", on=\"bfs_no\")\n",
    "\n",
    "import geopy.geocoders \n",
    "from geopy.distance import geodesic as GD\n",
    "\n",
    "r_cities = pd.read_csv(file_path + \"features_csv/relevant_cities.csv\")\n",
    "\n",
    "for i in range(merge_geo.shape[0]):\n",
    "    coords_1 = (merge_geo.N[i], merge_geo.E[i])\n",
    "    city_list = []\n",
    "    \n",
    "    for k in range(r_cities.shape[0]):\n",
    "        coords_2 = (r_cities.lat[k], r_cities.long[k])\n",
    "        city_list.append(GD(coords_1, coords_2).km)\n",
    "    \n",
    "    merge_geo.at[i, \"distance_to_nearest_city\"] = min(city_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bfs_no: has type int32\n",
      "month: has type object\n",
      "weekday: has type object\n",
      "packages: has type int32\n",
      "mean_age: has type float64\n",
      "total_pop: has type object\n",
      "share_0to14: has type float64\n",
      "share_15to19: has type float64\n",
      "share_20to39: has type float64\n",
      "share_40to64: has type float64\n",
      "share_65to79: has type float64\n",
      "share_above80: has type float64\n",
      "share_foreigners: has type float64\n",
      "share_catholics: has type object\n",
      "share_other_relig: has type object\n",
      "share_protestants: has type object\n",
      "unemployment_rate: has type float64\n",
      "taxpower: has type object\n",
      "share_tertiary: has type float64\n",
      "firms: has type float64\n",
      "E: has type float64\n",
      "N: has type float64\n",
      "distance_to_nearest_city: has type float64\n"
     ]
    }
   ],
   "source": [
    "# checking if all the column features have the right format \n",
    "for col in merge_geo.columns:\n",
    "    print(f\"{col}: has type {merge_geo[col].dtype}\")\n",
    "\n",
    "# ugh.. some features have type object let's change it to float\n",
    "wrong_type = [\"total_pop\", \"share_catholics\", \"share_other_relig\", \"share_protestants\"]\n",
    "for i in range(len(wrong_type)):\n",
    "    merge_geo[wrong_type[i]] = merge_geo[wrong_type[i]].str.replace(\"'\", \"\").astype(float)\n",
    "\n",
    "# save new master dataset with all features merged!\n",
    "# merge_geo.to_csv(\"C:/Users/patri/Downloads/packages_final.csv\", index=False)\n",
    "\n",
    "# THE FINAL DATASET LET'S GO\n",
    "packages_final = pd.read_csv(file_path + \"packages_final.csv\")\n",
    "packages_final.drop(columns=[\"bfs_no\", \"E\", \"N\"], inplace=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('dsf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "592bf600932a349e96e6ca7e32828db0724a5a3e4ed8104c48f42ee093d533c8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
